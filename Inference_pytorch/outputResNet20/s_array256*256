log/default/ADCprecision=5/batch_size=500/cellBit=4/dataset=cifar10/decreasing_lr=140,180/detect=0/grad_scale=8/inference=1/lr=0.01/mode=WAGE/model=ResNet20/onoffratio=10/seed=117/subArray=128/t=0/target=0/v=0/vari=0/wl_activate=8/wl_error=8/wl_grad=8/wl_weight=8
Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
Files already downloaded and verified
fan_in     27, float_limit 0.333333, float std 0.272166, quant limit 1.5, scale 4
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    576, float_limit 0.072169, float std 0.058926, quant limit 1.5, scale 16
fan_in    576, float_limit 0.072169, float std 0.058926, quant limit 1.5, scale 16
fan_in    576, float_limit 0.072169, float std 0.058926, quant limit 1.5, scale 16
fan_in    576, float_limit 0.072169, float std 0.058926, quant limit 1.5, scale 16
fan_in    576, float_limit 0.072169, float std 0.058926, quant limit 1.5, scale 16
fan_in     64, float_limit 0.216506, float std 0.176777, quant limit 1.5, scale 8
ERROR: SubArray Size is too large, which break the chip hierarchey, please decrease the SubArray size! 
quantize layer  Conv_0_
input_shape = (500, 3, 32, 32)
quantize layer  Conv3x3_1_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_2_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_3_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_4_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_5_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_6_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_7_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_8_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_9_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_10_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_11_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_12_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_13_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_14_
input_shape = (500, 64, 8, 8)
quantize layer  Conv3x3_15_
input_shape = (500, 64, 8, 8)
quantize layer  Conv3x3_16_
input_shape = (500, 64, 8, 8)
quantize layer  Conv3x3_17_
input_shape = (500, 64, 8, 8)
quantize layer  Conv3x3_18_
input_shape = (500, 64, 8, 8)
quantize layer  FC_19_
 --- Hardware Properties --- 
subArray size: 
128
ADC precision: 
5
cell precision: 
4
on/off ratio: 
10
variation: 
0
Test set: 
avg loss: 
2.1815545558929443
accuracy: 
26.969999313354492
