log/default/ADCprecision=5/batch_size=500/cellBit=4/dataset=cifar10/decreasing_lr=140,180/detect=0/grad_scale=8/inference=1/lr=0.01/mode=WAGE/model=ResNet20/onoffratio=10/seed=117/subArray=128/t=0/target=0/v=0/vari=0/wl_activate=8/wl_error=8/wl_grad=8/wl_weight=8
Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
Files already downloaded and verified
fan_in     27, float_limit 0.333333, float std 0.272166, quant limit 1.5, scale 4
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    144, float_limit 0.144338, float std 0.117851, quant limit 1.5, scale 8
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    288, float_limit 0.102062, float std 0.083333, quant limit 1.5, scale 16
fan_in    576, float_limit 0.072169, float std 0.058926, quant limit 1.5, scale 16
fan_in    576, float_limit 0.072169, float std 0.058926, quant limit 1.5, scale 16
fan_in    576, float_limit 0.072169, float std 0.058926, quant limit 1.5, scale 16
fan_in    576, float_limit 0.072169, float std 0.058926, quant limit 1.5, scale 16
fan_in    576, float_limit 0.072169, float std 0.058926, quant limit 1.5, scale 16
fan_in     64, float_limit 0.216506, float std 0.176777, quant limit 1.5, scale 8
------------------------------ FloorPlan --------------------------------

Tile and PE size are optimized to maximize memory utilization ( = memory mapped by synapse / total memory on chip)

Desired Conventional Mapped Tile Storage Size: 64x64
Desired Conventional PE Storage Size: 32x32
Desired Novel Mapped Tile Storage Size: 9x16x16
User-defined SubArray Size: 4x4

----------------- # of tile used for each layer -----------------
layer1: 4
layer2: 4
layer3: 4
layer4: 4
layer5: 4
layer6: 4
layer7: 4
layer8: 8
layer9: 16
layer10: 16
layer11: 16
layer12: 16
layer13: 16
layer14: 32
layer15: 64
layer16: 64
layer17: 64
layer18: 64
layer19: 64
layer20: 1

----------------- Speed-up of each layer ------------------
layer1: 4
layer2: 1
layer3: 1
layer4: 1
layer5: 1
layer6: 1
layer7: 1
layer8: 1
layer9: 1
layer10: 1
layer11: 1
layer12: 1
layer13: 1
layer14: 1
layer15: 1
layer16: 1
layer17: 1
layer18: 1
layer19: 1
layer20: 1

----------------- Utilization of each layer ------------------
layer1: 0.75
layer2: 1
layer3: 1
layer4: 1
layer5: 1
layer6: 1
layer7: 1
layer8: 1
layer9: 1
layer10: 1
layer11: 1
layer12: 1
layer13: 1
layer14: 1
layer15: 1
layer16: 1
layer17: 1
layer18: 1
layer19: 1
layer20: 0.625
Memory Utilization of Whole Chip: 99.7068 % 

---------------------------- FloorPlan Done ------------------------------



[NewSwitchMatrix] Error: pass gate height is even larger than the array height
ERROR: Height of subArray is even smaller than a single DFF !!! 
ERROR: Width of subArray is even smaller than a single DFF !!! 
[Adder] Error: A single adder width is even larger than the assigned width ! 
ERROR: Width of subArray is even smaller than a single DFF !!! 
[Adder] Error: A single adder width is even larger than the assigned width ! 
ERROR: Width of subArray is even smaller than a single DFF !!! 
[NewSwitchMatrix] Error: pass gate height is even larger than the array height
ERROR: Height of subArray is even smaller than a single DFF !!! 
ERROR: Width of subArray is even smaller than a single DFF !!! 
[Adder] Error: A single adder width is even larger than the assigned width ! 
ERROR: Width of subArray is even smaller than a single DFF !!! 
[Adder] Error: A single adder width is even larger than the assigned width ! 
ERROR: Width of subArray is even smaller than a single DFF !!! 
[Adder] Error: A single adder width is even larger than the assigned width ! 
ERROR: Width of subArray is even smaller than a single DFF !!! 
[NewSwitchMatrix] Error: pass gate height is even larger than the array height
ERROR: Height of subArray is even smaller than a single DFF !!! 
ERROR: Width of subArray is even smaller than a single DFF !!! 
[Adder] Error: A single adder width is even larger than the assigned width ! 
ERROR: Width of subArray is even smaller than a single DFF !!! 
[Adder] Error: A single adder width is even larger than the assigned width ! 
ERROR: Width of subArray is even smaller than a single DFF !!! 
[Adder] Error: A single adder width is even larger than the assigned width ! 
ERROR: Width of subArray is even smaller than a single DFF !!! 
-------------------------------------- Hardware Performance --------------------------------------
-------------------- Estimation of Layer 1 ----------------------
quantize layer  Conv_0_
input_shape = (500, 3, 32, 32)
quantize layer  Conv3x3_1_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_2_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_3_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_4_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_5_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_6_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_7_
input_shape = (500, 16, 32, 32)
quantize layer  Conv3x3_8_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_9_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_10_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_11_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_12_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_13_
input_shape = (500, 32, 16, 16)
quantize layer  Conv3x3_14_
input_shape = (500, 64, 8, 8)
quantize layer  Conv3x3_15_
input_shape = (500, 64, 8, 8)
quantize layer  Conv3x3_16_
input_shape = (500, 64, 8, 8)
quantize layer  Conv3x3_17_
input_shape = (500, 64, 8, 8)
quantize layer  Conv3x3_18_
input_shape = (500, 64, 8, 8)
quantize layer  FC_19_
 --- Hardware Properties --- 
subArray size: 
128
ADC precision: 
5
cell precision: 
4
on/off ratio: 
10
variation: 
0
Test set: 
avg loss: 
2.1815545558929443
accuracy: 
26.969999313354492
